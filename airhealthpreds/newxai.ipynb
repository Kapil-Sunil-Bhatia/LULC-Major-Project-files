{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data (replace with your actual data)\n",
    "df = pd.read_csv('global-air-pollution-dataset.csv')\n",
    "\n",
    "# Encode AQI Categories (Good=0, Moderate=1, Unhealthy=2)\n",
    "df['AQI Category'] = df['AQI Category'].map({'Good': 0, 'Moderate': 1, 'Unhealthy': 2, 'Unhealthy for Sensitive Groups': 3})\n",
    "\n",
    "# Select relevant features (SO2, NO2, PM10, PM2.5)\n",
    "X = df[['SO2 AQI Value', 'NO2 AQI Value', 'PM10 AQI Value', 'PM2.5 AQI Value']].values\n",
    "y = df['AQI Category'].values\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the dataset\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['AQI Category'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())  # Should show no missing values now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the features and target variable again\n",
    "X = df[['SO2 AQI Value', 'NO2 AQI Value', 'PM10 AQI Value', 'PM2.5 AQI Value']].values\n",
    "y = df['AQI Category'].values\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train Random Forest model\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def counterfactual_explanation(model, scaler, original_data, target_class, feature_names):\n",
    "    \"\"\"\n",
    "    Generate a counterfactual explanation for the given original data point\n",
    "    that would lead to a desired target class.\n",
    "    \n",
    "    Args:\n",
    "    - model: trained machine learning model\n",
    "    - scaler: scaler used for preprocessing the data\n",
    "    - original_data: original data point for which counterfactual is required\n",
    "    - target_class: the desired target class (e.g., 1 for 'Moderate')\n",
    "    - feature_names: list of feature names (SO2, NO2, PM10, PM2.5)\n",
    "    \n",
    "    Returns:\n",
    "    - counterfactual_data: adjusted feature values that change the prediction to target_class\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the objective function: the goal is to minimize the change required to predict the target_class\n",
    "    def objective_function(x):\n",
    "        # Rescale the input data point\n",
    "        adjusted_data = scaler.inverse_transform([x])\n",
    "        adjusted_prediction = model.predict(adjusted_data)[0]\n",
    "        # Minimize the difference between current prediction and target_class\n",
    "        return abs(adjusted_prediction - target_class)\n",
    "    \n",
    "    # Initial guess: the original data point\n",
    "    initial_guess = original_data\n",
    "    \n",
    "    # Optimize to minimize the difference between predicted class and target class\n",
    "    result = minimize(objective_function, initial_guess, bounds=[(0, 500)] * len(feature_names))\n",
    "    \n",
    "    # Return the adjusted features\n",
    "    counterfactual_data = scaler.inverse_transform([result.x])\n",
    "    return dict(zip(feature_names, counterfactual_data[0]))\n",
    "\n",
    "# Example Usage\n",
    "original_data = X_test[0]  # Take a sample from the test set\n",
    "target_class = 2  # Target class (e.g., 'Moderate' AQI category)\n",
    "feature_names = ['SO2 AQI Value', 'NO2 AQI Value', 'PM10 AQI Value', 'PM2.5 AQI Value']\n",
    "\n",
    "counterfactual = counterfactual_explanation(model, scaler, original_data, target_class, feature_names)\n",
    "print(\"Counterfactual Explanation:\", counterfactual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data to include only India\n",
    "df_india = df[df['Country'] == 'India']\n",
    "\n",
    "# Prepare the features and target variable again for the India dataset\n",
    "X_india = df_india[['SO2 AQI Value', 'NO2 AQI Value', 'PM10 AQI Value', 'PM2.5 AQI Value']].values\n",
    "y_india = df_india['AQI Category'].values\n",
    "\n",
    "# Split data into training and testing sets for India data\n",
    "X_train_india, X_test_india, y_train_india, y_test_india = train_test_split(X_india, y_india, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "X_train_india = scaler.fit_transform(X_train_india)\n",
    "X_test_india = scaler.transform(X_test_india)\n",
    "\n",
    "# Train Random Forest model on India data\n",
    "model.fit(X_train_india, y_train_india)\n",
    "\n",
    "# Example Usage for Counterfactual Explanation\n",
    "original_data_india = X_test_india[0]  # Take a sample from the India test set\n",
    "target_class = 1  # Target class (e.g., 'Unhealthy' AQI category, but you can change this)\n",
    "feature_names = ['SO2 AQI Value', 'NO2 AQI Value', 'PM10 AQI Value', 'PM2.5 AQI Value']\n",
    "\n",
    "# Generate counterfactual explanation for the selected India sample\n",
    "counterfactual_india = counterfactual_explanation(model, scaler, original_data_india, target_class, feature_names)\n",
    "print(\"Counterfactual Explanation for India:\", counterfactual_india)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load your dataset (replace this with your actual CSV file path)\n",
    "df = pd.read_csv('global-air-pollution-dataset.csv')  # replace 'your_data.csv' with the actual file name\n",
    "\n",
    "# Filter India country data\n",
    "india_df = df[df['Country'] == 'India']\n",
    "\n",
    "# Select the relevant columns (Pollutants and AQI Category)\n",
    "X = india_df[['SO2 AQI Value', 'PM10 AQI Value', 'NO2 AQI Value', 'PM2.5 AQI Value']].values\n",
    "y = india_df['AQI Category']\n",
    "\n",
    "# Label encode the AQI Category (e.g., 'Good', 'Moderate', 'Unhealthy')\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Function to generate counterfactual explanations with regularization\n",
    "def generate_counterfactual(X_original, target_class, model, lambda_reg=0.1, max_iter=1000, learning_rate=0.01):\n",
    "    \"\"\"\n",
    "    Generate a counterfactual explanation by adjusting the input features.\n",
    "    \"\"\"\n",
    "    # Ensure the original data is in float format for gradient descent\n",
    "    X_original = X_original.astype(np.float64)\n",
    "    \n",
    "    # Initialize the counterfactual with the original input\n",
    "    X_counterfactual = np.copy(X_original)\n",
    "    \n",
    "    # Gradient descent optimization loop\n",
    "    for _ in range(max_iter):\n",
    "        # Predict the current class\n",
    "        current_class = model.predict(X_counterfactual.reshape(1, -1))[0]\n",
    "        \n",
    "        # If the current class is the target class, we're done\n",
    "        if current_class == target_class:\n",
    "            break\n",
    "        \n",
    "        # Calculate the gradient of the loss function w.r.t. X' (counterfactual input)\n",
    "        # Loss function: L = ||X' - X||^2 + lambda * ||X'||_1\n",
    "        # Gradient of the first term (Euclidean distance)\n",
    "        grad_distance = 2 * (X_counterfactual - X_original)\n",
    "        \n",
    "        # Gradient of the regularization term (L1 norm)\n",
    "        grad_reg = lambda_reg * np.sign(X_counterfactual)\n",
    "        \n",
    "        # Total gradient\n",
    "        grad = grad_distance + grad_reg\n",
    "        \n",
    "        # Update the counterfactual using gradient descent\n",
    "        X_counterfactual -= learning_rate * grad\n",
    "        \n",
    "        # Clip the values to avoid extreme changes (keep the features within a valid range)\n",
    "        X_counterfactual = np.clip(X_counterfactual, 0, 500)  # Assuming AQI values are within this range\n",
    "        \n",
    "    return X_counterfactual\n",
    "\n",
    "# Example usage:\n",
    "original_sample = X_test[0]  # Sample input from the test set\n",
    "target_class = 1  # Target class ('Unhealthy' AQI category)\n",
    "counterfactual = generate_counterfactual(original_sample, target_class, model)\n",
    "\n",
    "print(\"Original Sample:\", original_sample)\n",
    "print(\"Counterfactual Sample:\", counterfactual)\n",
    "\n",
    "# Predict the counterfactual's AQI category\n",
    "predicted_class = model.predict(counterfactual.reshape(1, -1))[0]\n",
    "print(f\"Predicted Class for Counterfactual: {le.inverse_transform([predicted_class])[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# Define hyperparameters for Grid Search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  # Number of trees\n",
    "    'max_depth': [None, 10, 20, 30],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum samples to split a node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum samples required to be at a leaf node\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],  # Number of features to consider at each split\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV with cross-validation\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters found by GridSearchCV\n",
    "print(\"Best Parameters from Grid Search:\", grid_search.best_params_)\n",
    "\n",
    "# Use the best estimator found by grid search\n",
    "best_rf_model = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels for the test set using the fine-tuned model\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Classification Report (Precision, Recall, F1-Score)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# ROC-AUC Score (if it's a binary classification or multi-class)\n",
    "if len(np.unique(y_test)) == 2:  # Binary classification\n",
    "    roc_auc = roc_auc_score(y_test, best_rf_model.predict_proba(X_test)[:, 1])\n",
    "    print(\"ROC-AUC Score:\", roc_auc)\n",
    "else:\n",
    "    print(\"ROC-AUC cannot be computed for multi-class classification directly.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate counterfactual explanations with regularization\n",
    "def generate_counterfactual(X_original, target_class, best_rf_model, lambda_reg=0.1, max_iter=1000, learning_rate=0.01):\n",
    "    \"\"\"\n",
    "    Generate a counterfactual explanation by adjusting the input features.\n",
    "    \"\"\"\n",
    "    # Ensure the original data is in float format for gradient descent\n",
    "    X_original = X_original.astype(np.float64)\n",
    "    \n",
    "    # Initialize the counterfactual with the original input\n",
    "    X_counterfactual = np.copy(X_original)\n",
    "    \n",
    "    # Gradient descent optimization loop\n",
    "    for _ in range(max_iter):\n",
    "        # Predict the current class\n",
    "        current_class = best_rf_model.predict(X_counterfactual.reshape(1, -1))[0]\n",
    "        \n",
    "        # If the current class is the target class, we're done\n",
    "        if current_class == target_class:\n",
    "            break\n",
    "        \n",
    "        # Calculate the gradient of the loss function w.r.t. X' (counterfactual input)\n",
    "        # Loss function: L = ||X' - X||^2 + lambda * ||X'||_1\n",
    "        # Gradient of the first term (Euclidean distance)\n",
    "        grad_distance = 2 * (X_counterfactual - X_original)\n",
    "        \n",
    "        # Gradient of the regularization term (L1 norm)\n",
    "        grad_reg = lambda_reg * np.sign(X_counterfactual)\n",
    "        \n",
    "        # Total gradient\n",
    "        grad = grad_distance + grad_reg\n",
    "        \n",
    "        # Update the counterfactual using gradient descent\n",
    "        X_counterfactual -= learning_rate * grad\n",
    "        \n",
    "        # Clip the values to avoid extreme changes (keep the features within a valid range)\n",
    "        X_counterfactual = np.clip(X_counterfactual, 0, 500)  # Assuming AQI values are within this range\n",
    "        \n",
    "    return X_counterfactual\n",
    "\n",
    "# Example usage:\n",
    "original_sample = X_test[21]  # Sample input from the test set\n",
    "target_class = 2  # Target class ('Unhealthy' AQI category)\n",
    "counterfactual = generate_counterfactual(original_sample, target_class, best_rf_model)\n",
    "\n",
    "print(\"Original Sample:\", original_sample)\n",
    "print(\"Counterfactual Sample:\", counterfactual)\n",
    "\n",
    "# Predict the counterfactual's AQI category\n",
    "predicted_class = best_rf_model.predict(counterfactual.reshape(1, -1))[0]\n",
    "print(f\"Predicted Class for Counterfactual: {le.inverse_transform([predicted_class])[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aqi_info(aqi):\n",
    "    \"\"\"Determine AQI level and suggest measures to improve air quality.\"\"\"\n",
    "    if aqi <= 50:\n",
    "        level = \"Good\"\n",
    "        measures = [\n",
    "            \"Air quality is satisfactory.\",\n",
    "            \"Maintain current practices to keep air clean.\",\n",
    "            \"Promote green spaces and plant more trees.\",\n",
    "            \"Encourage use of renewable energy sources.\",\n",
    "            \"Continue community awareness programs to sustain good air quality.\",\n",
    "            \"Regularly monitor air quality and take preventive measures as needed.\",\n",
    "            \"Encourage local governments to maintain clean public spaces.\"\n",
    "        ]\n",
    "    elif aqi <= 100:\n",
    "        level = \"Moderate\"\n",
    "        measures = [\n",
    "            \"Air quality is acceptable but could be improved.\",\n",
    "            \"Reduce outdoor burning and vehicle emissions.\",\n",
    "            \"Encourage carpooling and use of public transport.\",\n",
    "            \"Limit the use of high-emission vehicles.\",\n",
    "            \"Expand green spaces and promote energy-efficient appliances.\",\n",
    "            \"Use fuel-efficient vehicles and conduct regular vehicle maintenance.\",\n",
    "            \"Promote the use of low-VOC (Volatile Organic Compound) products.\"\n",
    "        ]\n",
    "    elif aqi <= 150:\n",
    "        level = \"Unhealthy for Sensitive Groups\"\n",
    "        measures = [\n",
    "            \"Sensitive groups should reduce outdoor activities.\",\n",
    "            \"Minimize vehicle usage and promote cycling or walking.\",\n",
    "            \"Adopt cleaner fuels and energy-efficient appliances.\",\n",
    "            \"Implement stricter industrial emission controls.\",\n",
    "            \"Promote electric and hybrid vehicles and use cleaner cooking fuels.\",\n",
    "            \"Increase funding for air quality research and monitoring technologies.\",\n",
    "            \"Support local initiatives to improve waste management and recycling.\"\n",
    "        ]\n",
    "    elif aqi <= 200:\n",
    "        level = \"Unhealthy\"\n",
    "        measures = [\n",
    "            \"Everyone should limit prolonged outdoor exertion.\",\n",
    "            \"Reduce energy consumption at home and workplaces.\",\n",
    "            \"Avoid burning waste and encourage proper disposal.\",\n",
    "            \"Enhance green cover in urban areas to absorb pollutants.\",\n",
    "            \"Encourage the use of public transportation and renewable energy sources.\",\n",
    "            \"Implement pollution control measures during construction activities.\",\n",
    "            \"Collaborate with industries to adopt advanced pollution-reduction technologies.\"\n",
    "        ]\n",
    "    elif aqi <= 300:\n",
    "        level = \"Very Unhealthy\"\n",
    "        measures = [\n",
    "            \"Avoid outdoor activities and stay indoors as much as possible.\",\n",
    "            \"Use air purifiers indoors to maintain clean air.\",\n",
    "            \"Control industrial emissions and encourage renewable energy sources.\",\n",
    "            \"Implement stricter regulations on construction dust.\",\n",
    "            \"Deploy air-cleaning towers in highly polluted areas and monitor hotspots using drones.\",\n",
    "            \"Provide subsidies for solar panels and wind turbines to reduce reliance on fossil fuels.\",\n",
    "            \"Encourage the development of urban forests and green belts around cities.\"\n",
    "        ]\n",
    "    else:\n",
    "        level = \"Hazardous\"\n",
    "        measures = [\n",
    "            \"Health alert: Everyone should stay indoors and limit exposure.\",\n",
    "            \"Use high-quality air purifiers indoors.\",\n",
    "            \"Emergency reduction of emissions from vehicles and industries.\",\n",
    "            \"Encourage government actions for immediate pollution control.\",\n",
    "            \"Promote sustainable farming practices and reduce stubble burning.\",\n",
    "            \"Provide masks and health support to vulnerable populations.\",\n",
    "            \"Establish emergency air pollution response teams for critical areas.\"\n",
    "        ]\n",
    "\n",
    "    return level, measures\n",
    "\n",
    "# Main program\n",
    "def main():\n",
    "    try:\n",
    "        aqi = int(input(\"Enter the AQI value: \"))\n",
    "        level, measures = get_aqi_info(aqi)\n",
    "        print(f\"Air Quality Level: {level}\")\n",
    "        print(\"Measures:\")\n",
    "        for measure in measures:\n",
    "            print(f\"- {measure}\")\n",
    "    except ValueError:\n",
    "        print(\"Please enter a valid numeric AQI value.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
